# Copyright (c) 2013 Spotify AB
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License. You may obtain a copy of
# the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations under
# the License.
"""
Extension for generating Avro schemas from PySchema Record classes

Usage:

>>> class MyRecord(pyschema.Record):
>>>     foo = Text()
>>>     bar = Integer()
>>>
>>> [pyschema.contrib.avro.]get_schema_string(MyRecord)

'{"fields": [{"type": "string", "name": "foo"},
{"type": "long", "name": "bar"}],
"type": "record", "name": "MyRecord"}'

"""
from pyschema import core
from pyschema.types import Field, Boolean, Integer, Float
from pyschema.types import Bytes, Text, Enum, List, Map, SubRecord
import simplejson as json


Boolean.avro_type_name = "boolean"
Integer.avro_type_name = "long"
Float.avro_type_name = "double"
Bytes.avro_type_name = "bytes"
Text.avro_type_name = "string"
# "ENUM" is the avro 'type name' of all enums generated by pyschema
# this is pyschema convention, not avro, so it might change if
# need b
Enum.avro_type_name = "ENUM"
List.avro_type_name = "array"
Map.avro_type_name = "map"


@Field.mixin
class FieldMixin:
    def avro_type_schema(self):
        return [self.avro_type_name, "null"]

    def avro_dump(self, o):
        if o is None:
            return None
        else:
            # relying on the reference json dump behavior
            # could be a bit dangerous
            return {self.avro_type_name: self.dump(o)}

    def avro_load(self, o):
        if o is None:
            return None
        else:
            return self.load(o[self.avro_type_name])


@List.mixin
class ListMixin:
    def avro_type_schema(self):
        t = {
            "type": "array",
            "items": self.field_type.avro_type_schema()
        }
        if self.nullable:
            return [t, "null"]
        else:
            return t

    def avro_dump(self, obj):
        if obj is None:
            return None
        else:
            l = [self.field_type.avro_dump(o) for o in obj]
            if self.nullable:
                return {self.avro_type_name: l}
            else:
                return l

    def avro_load(self, obj):
        if obj is None:
            return None
        else:
            if self.nullable:
                obj = obj[self.avro_type_name]
            return [
                self.field_type.avro_load(o)
                for o in obj
            ]


### `Enum` extensions
@Enum.mixin
class EnumMixin:
    def avro_type_schema(self):
        return [
            {
                "type": "enum",
                "name": self.avro_type_name,
                "symbols": list(self.values)
            },
            "null"
        ]


@SubRecord.mixin
class SubRecordMixin:
    def avro_type_schema(self):
        return [get_schema_dict(self._record_class), "null"]

    @property
    def avro_type_name(self):
        return self._record_class._record_name

    def avro_dump(self, obj):
        return {self.avro_type_name: obj}

    def avro_load(self, obj):
        return from_json_compatible(
            self._record_class,
            obj[self.avro_type_name]
        )


@Map.mixin
class MapMixin:
    def avro_type_schema(self):
        assert isinstance(self.key_type, Text)
        m = {
            "type": "map",
            "values": self.value_type.avro_type_schema()
        }
        if self.nullable:
            return [m, "null"]
        else:
            return m

    def avro_dump(self, obj):
        if obj is None:
            return None
        else:
            m = dict([(
                # using json loader for key is kind of a hack
                # since this isn't an actual type in avro (always text)
                self.key_type.dump(k),
                self.value_type.avro_dump(v)
            ) for k, v in obj.iteritems()])
            if self.nullable:
                return {self.avro_type_name: m}
            else:
                return m

    def avro_load(self, obj):
        if obj is None:
            return None
        else:
            if self.nullable:
                obj = obj[self.avro_type_name]
            m = dict([(
                # using json loader for key is kind of a hack
                # since this isn't an actual type in avro (always text)
                self.key_type.load(k),
                self.value_type.avro_load(v)
            ) for k, v in obj.iteritems()])
            return m


# Schema generation
def get_schema_dict(record):
    avro_record = {
        "type": "record",
        "name": record._record_name,
    }
    avro_fields = []
    for field_name, field_type in record._schema:
        field_spec = {
            "name": field_name,
            "type": field_type.avro_type_schema()
        }
        avro_fields.append(field_spec)

    avro_record["fields"] = avro_fields
    return avro_record


def get_schema_string(record):
    return json.dumps(get_schema_dict(record))


class OrderedPySchemaJsonEncoder(json.JSONEncoder):
    """ Custom JSONEncoder for preserving field order
    in serialized json strings (from schema definition)

    This is required by some configurations of the java Avro JsonDecoder
    """
    def _make_dict(self, items):
        string_parts = []
        for key, val in items:
            string_parts.append(''.join((
                self.encode(key),
                self.key_separator,
                self.encode(val)
            )))
        return ''.join((
            '{',
            self.item_separator.join(string_parts),
            '}'
        ))

    def encode_record(self, record):
        keyvals = []
        for name, fieldtype in record._schema:
            value = getattr(record, name)
            keyvals.append((
                name,
                fieldtype.avro_dump(value)
            ))
        return self._make_dict(keyvals)

    def encode(self, x):
        if isinstance(x, core.Record):
            return self.encode_record(x)
        elif isinstance(x, (list, tuple)):
            return ''.join((
                '[',
                self.item_separator.join(
                    self.encode(v) for v in x
                ),
                ']'
            ))
        elif isinstance(x, dict):
            return self._make_dict(x.iteritems())

        return super(OrderedPySchemaJsonEncoder, self).encode(x)


ordered_json_encoder = OrderedPySchemaJsonEncoder()


def dumps(record):
    return ordered_json_encoder.encode(record)


def from_json_compatible(record_class, dct):
    field_values = {}
    schema = record_class._schema
    for field_name, field_type in schema:
        if field_name in dct:
            field_values[field_name] = field_type.avro_load(dct[field_name])

    return record_class(**field_values)


def loads(s, record_store=None, record_class=None):
    return core.loads(s, record_store, record_class, from_json_compatible)
